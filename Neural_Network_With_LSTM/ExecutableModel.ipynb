{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, OrderedDict,defaultdict\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import pickle\n",
    "# from spacy.vocab import Vocab\n",
    "# from spacy.language import Language\n",
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making files\n",
    "from_lang='english'\n",
    "to_lang='english' \n",
    "mapping_path='dataset/Cross_word_mapping/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(from_lang):\n",
    "    \n",
    "    punc_table = str.maketrans({key: None for key in string.punctuation})\n",
    "    sentences = []\n",
    "    targets = []\n",
    "    count =0;\n",
    "    \n",
    "    with open('dataset/'+str(from_lang)+'_word_def.txt', 'r') as filee:\n",
    "        \n",
    "        for i, line in enumerate(filee):\n",
    "            words = line.strip('\\n').split('\\t')\n",
    "            word = words[0]\n",
    "            definitions = words[1].split(';')\n",
    "            for definition in definitions:\n",
    "                definition = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", definition).replace('  ', ' ')\n",
    "                temp_word_list = definition.translate(punc_table).lower().split(' ')\n",
    "                temp_word_list = list(filter(None, temp_word_list))\n",
    "                mid_sent=['<start>'] + temp_word_list + ['<end>']\n",
    "                if mid_sent in sentences:\n",
    "                    continue\n",
    "                sentences.append(['<start>'] + temp_word_list + ['<end>'])\n",
    "                targets.append(word)\n",
    "    WORD=[]\n",
    "    for word_sublist in sentences:\n",
    "        for word in word_sublist:\n",
    "            WORD.append(word)\n",
    "    words=WORD\n",
    "    inf = float('inf')\n",
    "    frequency_dict = OrderedDict({'<end>': inf, '<start>': inf})\n",
    "    words_frequency_dict = sorted(Counter(words).most_common(None), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    defs_frequency_dict = sorted(Counter(targets).most_common(None), key=lambda x:x[1], reverse=True)\n",
    "    frequency_dict.update(words_frequency_dict)\n",
    "    frequency_dict.update(defs_frequency_dict)\n",
    "    frequency_dict.move_to_end('<start>', last=False)\n",
    "\n",
    "    word2idx = OrderedDict([(item[0], i) for i,item in enumerate(frequency_dict.items())])\n",
    "    idx2word = dict(zip(word2idx.values(), word2idx.keys()))\n",
    "    \n",
    "    return sentences, targets, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, targets, word2idx, idx2word = data(from_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/divyani/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/'+from_lang+'.h5')\n",
    "# Check its architecture\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data_lang.csv\")\n",
    "# data=np.array(data)\n",
    "data_len=len(data)\n",
    "path=\"dataset/Cross_word_mapping/\"\n",
    "\n",
    "english_hindi=defaultdict(list)\n",
    "hindi_english=defaultdict(list)\n",
    "english_marathi=defaultdict(list)\n",
    "marathi_english=defaultdict(list)\n",
    "english_punjabi=defaultdict(list)\n",
    "punjabi_english=defaultdict(list)\n",
    "english_bengali=defaultdict(list)\n",
    "bengali_english=defaultdict(list)\n",
    "hindi_marathi=defaultdict(list)\n",
    "marathi_hindi=defaultdict(list)\n",
    "hindi_punjabi=defaultdict(list)\n",
    "punjabi_hindi=defaultdict(list)\n",
    "hindi_bengali=defaultdict(list)\n",
    "bengali_hindi=defaultdict(list)\n",
    "marathi_punjabi=defaultdict(list)\n",
    "punjabi_marathi=defaultdict(list)\n",
    "marathi_bengali=defaultdict(list)\n",
    "bengali_marathi=defaultdict(list)\n",
    "punjabi_bengali=defaultdict(list)\n",
    "bengali_punjabi=defaultdict(list)\n",
    "\n",
    "df=data[['english','hindi','marathi','punjabi','bengali']]\n",
    "\n",
    "def word_mapping(word_line):\n",
    "    word_line=str(word_line)\n",
    "    word_line=word_line[1:len(word_line)-1]\n",
    "    word_line=word_line.split(',')\n",
    "    word_return=[]\n",
    "    for word in word_line:\n",
    "        word=word.strip()\n",
    "        word=word[1:len(word)-1]\n",
    "        word_return.append(word)\n",
    "    return word_return\n",
    "\n",
    "df=np.array(df)\n",
    "#preparation for word mapping mapping\n",
    "for i in range(0,len(df)):\n",
    "    english=word_mapping(df[i][0])\n",
    "    hindi=word_mapping(df[i][1])\n",
    "    punjabi=word_mapping(df[i][3])\n",
    "    marathi=word_mapping(df[i][2])\n",
    "    bengali=word_mapping(df[i][4])\n",
    "    for word in english:\n",
    "        english_hindi[word].append(hindi)\n",
    "        english_punjabi[word].append(punjabi)\n",
    "        english_marathi[word].append(marathi)\n",
    "        english_bengali[word].append(bengali)\n",
    "    for word in hindi:\n",
    "        hindi_english[word].append(english)\n",
    "        hindi_punjabi[word].append(punjabi)\n",
    "        hindi_marathi[word].append(marathi)\n",
    "        hindi_bengali[word].append(bengali)\n",
    "    for word in punjabi:\n",
    "        punjabi_hindi[word].append(hindi)\n",
    "        punjabi_english[word].append(english)\n",
    "        punjabi_marathi[word].append(marathi)\n",
    "        punjabi_bengali[word].append(bengali)\n",
    "    for word in marathi:\n",
    "        marathi_hindi[word].append(hindi)\n",
    "        marathi_punjabi[word].append(punjabi)\n",
    "        marathi_english[word].append(english)\n",
    "        marathi_bengali[word].append(bengali)\n",
    "    for word in bengali:\n",
    "        bengali_hindi[word].append(hindi)\n",
    "        bengali_punjabi[word].append(punjabi)\n",
    "        bengali_marathi[word].append(marathi)\n",
    "        bengali_english[word].append(english)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosslist1=['english','hindi','marathi','punjabi','bengali']\n",
    "crosslist2=['english','hindi','marathi','punjabi','bengali']\n",
    "listofdict=[english_hindi,english_punjabi,english_marathi,english_bengali,hindi_english,hindi_punjabi,hindi_marathi\\\n",
    "            ,hindi_bengali,punjabi_hindi,punjabi_english,punjabi_marathi,punjabi_bengali,marathi_hindi,\\\n",
    "            marathi_punjabi,marathi_english,marathi_bengali,bengali_hindi,bengali_punjabi,bengali_marathi,bengali_english]\n",
    "listofdictname={'english_hindi':0,'english_punjabi':1,'english_marathi':2,'english_bengali':3,'hindi_english':4,\\\n",
    "                'hindi_punjabi':5,'hindi_marathi':6,'hindi_bengali':7,'punjabi_hindi':8,'punjabi_english':9,\\\n",
    "                'punjabi_marathi':10,'punjabi_bengali':11,'marathi_hindi':12,'marathi_punjabi':13,'marathi_english':14,\\\n",
    "                'marathi_bengali':15,'bengali_hindi':16,'bengali_punjabi':17,'bengali_marathi':18,'bengali_english':19}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data_lang.csv\")\n",
    "train=train[[\"english\",\"english_gloss\"]]\n",
    "X=np.array(train['english_gloss'])\n",
    "X_label=np.array(train['english'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp={}\n",
    "for x in X_label:\n",
    "    temp=x[1:len(x)-1]\n",
    "    temp=temp.split(',')\n",
    "    for word in temp:\n",
    "        word=word[1:len(word)-1]\n",
    "        mp[word]=x;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rich=pd.read_csv(\"dataset_richa.csv\",header=None)\n",
    "target=np.array(data_rich[0])\n",
    "defi=np.array(data_rich[1])\n",
    "test_data=[]\n",
    "test_label=[]\n",
    "for i in range(0,len(target)):\n",
    "    if(target[i] in mp):\n",
    "        temp=mp[target[i]]\n",
    "        temp=temp[1:len(temp)-1]\n",
    "        temp=temp.split(',')\n",
    "        df=[]\n",
    "        for word in temp:\n",
    "            word=word.strip()\n",
    "            word=word[1:len(word)-1]\n",
    "            df.append(word)\n",
    "        df.append(target[i])\n",
    "        test_data.append(df)\n",
    "        test_label.append(defi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict=[]\n",
    "def find_word(definition):\n",
    "    words = definition.split(' ')\n",
    "    idxs = []\n",
    "    meaning=[]\n",
    "    for word in words:\n",
    "        if(word in word2idx):\n",
    "            idxs.append(word2idx[word])\n",
    "    idxs = np.array([0] + idxs + [1]).reshape((1,len(idxs) + 2))\n",
    "    prediction = model.predict(idxs, verbose=0)\n",
    "\n",
    "    index = np.argmax(prediction)\n",
    "#     print(index)\n",
    "    \n",
    "    meaning=idx2word[index]\n",
    "    test_predict.append(meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in test_label:\n",
    "    find_word(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n"
     ]
    }
   ],
   "source": [
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['war', 'warfare', 'war'] transaction\n",
      "['slow', 'slow'] hasty\n",
      "['money', 'money'] cash\n",
      "['immediately', 'instantly', 'straightaway', 'straight_off', 'directly', 'now', 'right_away', 'at_once', 'forthwith', 'in_real_time', 'like_a_shot', 'immediately'] over_and_over\n",
      "['initially', 'ab_initio', 'at_first', 'at_the_start', 'initially'] over_and_over\n",
      "['nearby', 'nearby'] hen\n",
      "['time', 'time'] outcaste\n",
      "['year', 'year'] tax\n",
      "['people', 'populate', 'people'] populace\n",
      "['day', 'twenty-four_hours', 'twenty-four_hour_period', '24-hour_interval', 'solar_day', 'mean_solar_day', 'day'] day\n",
      "['man', 'adult_male', 'man'] humanity\n",
      "['thing', 'thing'] called\n",
      "['work', 'work'] adapted\n",
      "['child', 'kid', 'youngster', 'minor', 'shaver', 'nipper', 'small_fry', 'tiddler', 'tike', 'tyke', 'fry', 'nestling', 'child'] middle_age\n",
      "['life', 'life'] July\n",
      "['world', 'human_race', 'humanity', 'humankind', 'human_beings', 'humans', 'mankind', 'man', 'world'] acre\n",
      "['back', 'backward', 'backwards', 'rearward', 'rearwards', 'back'] psalm\n",
      "['acceptable', 'accepted', 'acceptable'] agreement\n",
      "['honest', 'honorable', 'honest'] critical\n",
      "['sound', 'sound'] prevail\n",
      "['history', 'account', 'chronicle', 'story', 'history'] humanity\n",
      "['art', 'artistic_creation', 'artistic_production', 'art'] illegal\n",
      "['world', 'human_race', 'humanity', 'humankind', 'human_beings', 'humans', 'mankind', 'man', 'world'] acre\n",
      "['map', 'map'] Vietnam\n",
      "['two', '2', 'ii', 'two'] at_least\n",
      "['family', 'family_unit', 'family'] sugar\n",
      "['government', 'authorities', 'regime', 'government'] protagonist\n",
      "['health', 'health'] peanut\n",
      "['system', 'system'] sonography\n",
      "['year', 'year'] tax\n",
      "['music', 'music'] jaundice\n",
      "['person', 'individual', 'someone', 'somebody', 'mortal', 'soul', 'person'] islander\n",
      "['reading', 'reading'] exam\n",
      "['method', 'method'] undetermined\n",
      "['data', 'information', 'data'] cite\n",
      "['food', 'nutrient', 'food'] bonduc\n",
      "['law', 'law'] mineralogy\n",
      "['bird', 'bird'] challenge\n",
      "['literature', 'literature'] museum\n",
      "['software', 'software_program', 'computer_software', 'software_system', 'software_package', 'package', 'software'] autocracy\n",
      "['control', 'control'] define\n",
      "['power', 'powerfulness', 'power'] undenominational\n",
      "['ability', 'power', 'ability'] 'cinch\\\n",
      "['love', 'love'] compunction\n",
      "['science', 'scientific_discipline', 'science'] adjudicator\n",
      "['library', 'library'] karat\n",
      "['nature', 'nature'] physique\n",
      "['product', 'mathematical_product', 'product'] somewhere\n",
      "['idea', 'thought', 'idea'] two_hundred\n",
      "['area', 'expanse', 'surface_area', 'area'] dissection\n",
      "['activity', 'activity'] jute\n",
      "['industry', 'industry'] aquatic\n",
      "['thing', 'thing'] called\n",
      "['community', 'community'] adapted\n",
      "['safety', 'refuge', 'safety'] infective\n",
      "['quality', 'quality'] virtue\n",
      "['development', 'evolution', 'development'] company\n",
      "['week', 'hebdomad', 'week'] eight\n",
      "['security', 'security_measures', 'security'] caution\n",
      "['country', 'state', 'land', 'country'] path\n",
      "['movie', 'film', 'picture', 'moving_picture', 'moving-picture_show', 'motion_picture', 'motion-picture_show', 'picture_show', 'pic', 'flick', 'movie'] polish\n",
      "['organization', 'organisation', 'organization'] division\n",
      "['policy', 'insurance_policy', 'insurance', 'policy'] stoic\n",
      "['series', 'series'] negative\n",
      "['basis', 'base', 'foundation', 'fundament', 'groundwork', 'cornerstone', 'basis'] unambitious\n",
      "['boyfriend', 'fellow', 'beau', 'swain', 'young_man', 'boyfriend'] roll_in_the_hay\n",
      "['direction', 'instruction', 'direction'] protection\n",
      "['technology', 'engineering', 'technology'] budget\n",
      "['paper', 'paper'] dill\n",
      "['child', 'kid', 'youngster', 'minor', 'shaver', 'nipper', 'small_fry', 'tiddler', 'tike', 'tyke', 'fry', 'nestling', 'child'] middle_age\n",
      "['month', 'month'] summer\n",
      "['truth', 'the_true', 'verity', 'trueness', 'truth'] inferiority\n",
      "['writing', 'committal_to_writing', 'writing'] exam\n",
      "['department', 'section', 'department'] obstinate\n",
      "['goal', 'end', 'goal'] exercise\n",
      "['news', 'news'] reported\n",
      "['audience', 'audience'] lesson\n",
      "['income', 'income'] design\n",
      "['marriage', 'wedding', 'marriage_ceremony', 'marriage'] mister\n",
      "['failure', 'failure'] scratch_up\n",
      "['meaning', 'substance', 'meaning'] pronunciation\n",
      "['philosophy', 'philosophy'] program\n",
      "['chemistry', 'chemical_science', 'chemistry'] foundation_stone\n",
      "['energy', 'energy'] costume\n",
      "['success', 'success'] help\n",
      "['education', 'education'] application\n",
      "['moment', 'minute', 'second', 'bit', 'moment'] ancient\n",
      "['painting', 'house_painting', 'painting'] frame\n",
      "['politics', 'politics'] Sama-Veda\n",
      "['decision', 'determination', 'conclusion', 'decision'] accessible\n",
      "['property', 'belongings', 'holding', 'material_possession', 'property'] bodily\n",
      "['shopping', 'shopping'] dazzle\n",
      "['wood', 'wood'] inauguration\n",
      "['competition', 'contention', 'rivalry', 'competition'] tennis\n",
      "['distribution', 'distribution'] deficiency\n",
      "['office', 'office_staff', 'office'] permanent\n",
      "['population', 'population'] human_race\n",
      "['president', 'president'] Keystone_State\n",
      "['driver', 'driver'] coachman\n",
      "['flight', 'flying', 'flight'] experience\n",
      "['length', 'length'] microscope\n",
      "['magazine', 'mag', 'magazine'] literature\n",
      "['newspaper', 'paper', 'newspaper'] ignite\n",
      "['relationship', 'human_relationship', 'relationship'] visibility\n",
      "['teaching', 'instruction', 'pedagogy', 'teaching'] chapter\n",
      "['cell', 'cubicle', 'cell'] cell\n",
      "['lake', 'lake'] island\n",
      "['member', 'member'] center\n",
      "['message', 'message'] prove\n",
      "['scene', 'scene'] habitat\n",
      "['appearance', 'show', 'appearance'] protection\n",
      "['association', 'association'] rebellion\n",
      "['death', 'decease', 'expiry', 'death'] interview\n",
      "['discussion', 'give-and-take', 'word', 'discussion'] unit_of_measurement\n",
      "['inflation', 'rising_prices', 'inflation'] fitness\n",
      "['insurance', 'insurance'] cartoon\n",
      "['advice', 'advice'] tactically\n",
      "['blood', 'blood'] spinal_cord\n",
      "['effort', 'elbow_grease', 'exertion', 'travail', 'sweat', 'effort'] kingdom\n",
      "['expression', 'look', 'aspect', 'facial_expression', 'face', 'expression'] homogeneous\n",
      "['opinion', 'sentiment', 'persuasion', 'view', 'thought', 'opinion'] fiction\n",
      "['responsibility', 'responsibleness', 'responsibility'] give_up\n",
      "['skill', 'science', 'skill'] consent\n",
      "['statement', 'statement'] talking(a)\n",
      "['application', 'application'] fabric\n",
      "['city', 'metropolis', 'urban_center', 'city'] thumping\n",
      "['estate', 'estate'] contaminated\n",
      "['foundation', 'foundation'] seismograph\n",
      "['heart', 'pump', 'ticker', 'heart'] odd\n",
      "['recipe', 'formula', 'recipe'] concoction\n",
      "['collection', 'aggregation', 'accumulation', 'assemblage', 'collection'] shooting\n",
      "['depression', 'impression', 'imprint', 'depression'] castigation\n",
      "['imagination', 'imaginativeness', 'vision', 'imagination'] imagination\n",
      "['setting', 'background', 'scope', 'setting'] fear\n",
      "['agency', 'federal_agency', 'government_agency', 'bureau', 'office', 'authority', 'agency'] servant\n",
      "['college', 'college'] indistinct\n",
      "['connection', 'link', 'connectedness', 'connection'] qualification\n",
      "['criticism', 'critique', 'criticism'] debt\n",
      "['description', 'verbal_description', 'description'] message\n",
      "['memory', 'memory'] planning\n",
      "['solution', 'solution'] prickle\n",
      "['administration', 'disposal', 'administration'] smartness\n",
      "['aspect', 'facet', 'aspect'] midmost\n",
      "['director', 'manager', 'managing_director', 'director'] chief\n",
      "['personality', 'personality'] bad\n",
      "['psychology', 'psychological_science', 'psychology'] superficial\n",
      "['recommendation', 'testimonial', 'good_word', 'recommendation'] authoritatively\n",
      "['argument', 'argumentation', 'debate', 'argument'] anger\n",
      "['contract', 'contract'] island\n",
      "['loss', 'loss'] measuring_instrument\n",
      "['possession', 'ownership', 'possession'] behavior\n",
      "['preparation', 'readying', 'preparation'] crossbreed\n",
      "['steak', 'steak'] vocative\n",
      "['agreement', 'arrangement', 'agreement'] accordingly\n",
      "['cancer', 'malignant_neoplastic_disease', 'cancer'] swallow\n",
      "['engineering', 'engineering_science', 'applied_science', 'technology', 'engineering'] carefree\n",
      "['preference', 'penchant', 'predilection', 'taste', 'preference'] biased\n",
      "['region', 'region'] consecration\n",
      "['virus', 'virus'] white_flag\n",
      "['classroom', 'schoolroom', 'classroom'] funeral\n",
      "['delivery', 'bringing', 'delivery'] guidance\n",
      "['device', 'device'] ambitious\n",
      "['difficulty', 'difficultness', 'difficulty'] obstruction\n",
      "['election', 'election'] election\n",
      "['engine', 'engine'] Sudanese_pound\n",
      "['guidance', 'counsel', 'counseling', 'counselling', 'direction', 'guidance'] Sun_Myung_Moon\n",
      "['protection', 'protection'] company\n",
      "['suggestion', 'proposition', 'proffer', 'suggestion'] propose\n",
      "['tension', 'tenseness', 'stress', 'tension'] elasticity\n",
      "['anxiety', 'anxiousness', 'anxiety'] mislead\n",
      "['atmosphere', 'air', 'atmosphere'] atmosphere\n",
      "['awareness', 'sentience', 'awareness'] audit\n",
      "['climate', 'clime', 'climate'] long-run\n",
      "['confusion', 'mix-up', 'confusion'] heading\n",
      "['construction', 'building', 'construction'] thumping\n",
      "['elevator', 'lift', 'elevator'] clustering\n",
      "['guest', 'invitee', 'guest'] social_worker\n",
      "['height', 'tallness', 'height'] perpendicular\n",
      "['leadership', 'leading', 'leadership'] blind\n",
      "['operation', 'procedure', 'operation'] Jesus\n",
      "['recording', 'transcription', 'recording'] barbed\n",
      "['transportation', 'transfer', 'transferral', 'conveyance', 'transportation'] eviction\n",
      "['cousin', 'first_cousin', 'cousin-german', 'full_cousin', 'cousin'] cousin\n",
      "['editor', 'editor_in_chief', 'editor'] shore\n",
      "['excitement', 'excitation', 'inflammation', 'fervor', 'fervour', 'excitement'] exuberance\n",
      "['extent', 'extent'] over\n",
      "['feedback', 'feedback'] 'okra\\\n",
      "['guitar', 'guitar'] keyboard\n",
      "['leader', 'leader'] swayer\n",
      "['presentation', 'presentment', 'demonstration', 'presentation'] informal\n",
      "['promotion', 'promotion'] one\n",
      "['reflection', 'reflexion', 'reflection'] reaction\n",
      "['session', 'session'] badger\n",
      "['singer', 'vocalist', 'vocalizer', 'vocaliser', 'singer'] chief\n",
      "['tennis', 'lawn_tennis', 'tennis'] return\n",
      "['basket', 'handbasket', 'basket'] molasses\n",
      "['bonus', 'incentive', 'bonus'] get_around\n",
      "['cabinet', 'locker', 'storage_locker', 'cabinet'] guidance\n",
      "['childhood', 'childhood'] cleanness\n",
      "['church', 'church_building', 'church'] lecture\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,200):\n",
    "    print(test_data[i],test_predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18\n"
     ]
    }
   ],
   "source": [
    "count=0;\n",
    "for i in range(0,848):\n",
    "    if test_predict[i] in test_data[i]:\n",
    "        count+=1\n",
    "print(count/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# print(accuracy_score(test_data,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['पेनाल्टी', 'दंड', 'सज़ा', 'सजा', 'दण्ड']\n"
     ]
    }
   ],
   "source": [
    "temp=listofdict[listofdictname[from_lang+'_'+to_lang]][meaning]\n",
    "ans=[]\n",
    "for line in temp:\n",
    "    for word in line:\n",
    "        ans.append(word)\n",
    "        if(len(ans)>4):\n",
    "            break\n",
    "    if(len(ans)>4):\n",
    "        break\n",
    "print(ans)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
